{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPAYwwBvUCnp",
        "outputId": "1ca3c95b-2900-4bdd-fa3c-fa7012764af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 53.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])\n",
        "train_and_valid_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"datasets\", train=True, download=True, transform=toTensor)\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"datasets\", train=False, download=True, transform=toTensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "train_set, valid_set = torch.utils.data.random_split(\n",
        "    train_and_valid_set, [45_000, 5_000]\n",
        ")"
      ],
      "metadata": {
        "id": "N5aeum5dp0PG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle=True )\n",
        "valid_loader = DataLoader(valid_set, batch_size = batch_size, shuffle=False )\n",
        "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle=False )"
      ],
      "metadata": {
        "id": "Wk5wb3pS9bYO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def use_he_init(module):\n",
        "  if isinstance(module, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(module.weight)\n",
        "    nn.init.zeros_(module.bias)"
      ],
      "metadata": {
        "id": "_gFEANnypLkl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_model(n_hidden, n_neurons, n_inputs, n_outputs):\n",
        "\n",
        "  layers = [nn.Flatten(), nn.Linear(n_inputs, n_neurons), nn.SiLU() ]\n",
        "\n",
        "  for _ in range(n_hidden - 1):\n",
        "    layers += [nn.Linear(n_neurons, n_neurons), nn.SiLU()]\n",
        "\n",
        "  layers += [nn.Linear(n_neurons, n_outputs)]\n",
        "  model = torch.nn.Sequential(*layers)\n",
        "  model.apply(use_he_init)\n",
        "  return model\n",
        "\n",
        "# Creating deep neural network using function"
      ],
      "metadata": {
        "id": "JnUylLuSq9Et"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = deep_model(\n",
        "    n_hidden = 20, n_neurons = 100, n_inputs = 3 * 32 * 32, n_outputs = 10\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "SrWZgn2FtO6Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_tm(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric.update(y_pred, y_batch)\n",
        "    return metric.compute()\n",
        "\n",
        "# Evaluation Function"
      ],
      "metadata": {
        "id": "bYJ5JC6O3z7N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKBeuIpIBQwG",
        "outputId": "a9c5bcf4-bd96-433e-9273-e197bab0c72b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.7.0\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cpu)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import optuna\n",
        "\n",
        "def train_with_early_stopping(model, optimizer, loss_fn, metric, train_loader, valid_loader,\n",
        "                              n_epochs, device, patience=10, checkpoint_path=None, scheduler=None, trial=None):\n",
        "\n",
        "  checkpoint_path = checkpoint_path or \"my_checkpoint.pt\"\n",
        "  history = {\"train_losses\": [], \"train_metrics\":[], \"valid_metrics\":[]}\n",
        "  best_metric = 0.0\n",
        "  patience_counter = 0\n",
        "  file_saved = False\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    total_loss = 0.0\n",
        "    metric.reset()\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "\n",
        "    for x_batch, y_batch in train_loader:\n",
        "      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(x_batch)\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss += loss.item()\n",
        "      metric.update(y_pred, y_batch)\n",
        "\n",
        "    train_metric = metric.compute()\n",
        "    if isinstance(train_metric, torch.Tensor):\n",
        "        train_metric = train_metric.item()\n",
        "\n",
        "    valid_metric = evaluate_tm(model, valid_loader, metric)\n",
        "\n",
        "    if trial is not None:\n",
        "        trial.report(valid_metric, epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    if valid_metric > best_metric:\n",
        "      best_metric = valid_metric\n",
        "      best = \" (best)\"\n",
        "      patience_counter = 0\n",
        "\n",
        "      if trial is None:\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        file_saved = True\n",
        "    else:\n",
        "      patience_counter += 1\n",
        "      best = \"\"\n",
        "\n",
        "    t1 = time.time()\n",
        "    history[\"train_losses\"].append(total_loss / len(train_loader))\n",
        "    history[\"train_metrics\"].append(train_metric)\n",
        "    history[\"valid_metrics\"].append(valid_metric)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "          f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "          f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "          f\"valid metric: {history['valid_metrics'][-1]:.4f}{best}\"\n",
        "          f\" in {t1 - t0:.1f}s\"\n",
        "    )\n",
        "\n",
        "    if scheduler is not None:\n",
        "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "            scheduler.step(valid_metric)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(\"Early stopping!\")\n",
        "        break\n",
        "\n",
        "  if trial is None and file_saved:\n",
        "      model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "  return best_metric\n"
      ],
      "metadata": {
        "id": "-_xX-1nct-4H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Hyperparams\n",
        "    n_hidden = trial.suggest_int(\"n_hidden\", 1, 5)\n",
        "    n_neurons = trial.suggest_int(\"n_neurons\", 256, 1024)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"NAdam\"])\n",
        "\n",
        "    model = deep_model(n_hidden, n_neurons, 3072, 10).to(device)\n",
        "\n",
        "    optimizer_class = getattr(optim, optimizer_name)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "    best_accuracy = train_with_early_stopping(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=criterion,\n",
        "        metric=metric,\n",
        "        train_loader=train_loader,\n",
        "        valid_loader=valid_loader,\n",
        "        n_epochs=10,\n",
        "        patience=3,\n",
        "        device=device,\n",
        "        trial=trial\n",
        "    )\n",
        "\n",
        "    return best_accuracy"
      ],
      "metadata": {
        "id": "NItcYmaS3_1f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=2)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
        "\n",
        "print(\"--- Starting Hyperparameter Search ---\")\n",
        "\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"\\n --- Optimization Complete ---\")\n",
        "print(f\"Best Accuracy Found: {study.best_trial.value:.4f}\")\n",
        "print(\"Best Hyperparameters:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUNCrP4LD9IA",
        "outputId": "7b2bc9fa-ee4d-41ae-c173-5f022893b820"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:25:58,241] A new study created in memory with name: no-name-ff176aae-809b-43e2-ac77-c2339f796369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Hyperparameter Search ---\n",
            "Epoch 1/10, train loss: 1.8636, train metric: 0.3432, valid metric: 0.3916 (best) in 28.7s\n",
            "Epoch 2/10, train loss: 1.6471, train metric: 0.4132, valid metric: 0.4018 (best) in 24.0s\n",
            "Epoch 3/10, train loss: 1.5687, train metric: 0.4440, valid metric: 0.4732 (best) in 24.7s\n",
            "Epoch 4/10, train loss: 1.4972, train metric: 0.4742, valid metric: 0.4742 (best) in 24.3s\n",
            "Epoch 5/10, train loss: 1.4525, train metric: 0.4834, valid metric: 0.4836 (best) in 24.3s\n",
            "Epoch 6/10, train loss: 1.4147, train metric: 0.5009, valid metric: 0.4894 (best) in 24.3s\n",
            "Epoch 7/10, train loss: 1.3846, train metric: 0.5106, valid metric: 0.5006 (best) in 24.2s\n",
            "Epoch 8/10, train loss: 1.3487, train metric: 0.5235, valid metric: 0.4978 in 24.6s\n",
            "Epoch 9/10, train loss: 1.3339, train metric: 0.5296, valid metric: 0.4942 in 24.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:30:05,906] Trial 0 finished with value: 0.5148000121116638 and parameters: {'n_hidden': 1, 'n_neurons': 759, 'lr': 0.000474962015711461, 'optimizer': 'AdamW'}. Best is trial 0 with value: 0.5148000121116638.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.3059, train metric: 0.5394, valid metric: 0.5148 (best) in 24.1s\n",
            "Epoch 1/10, train loss: 2.7742, train metric: 0.2523, valid metric: 0.2860 (best) in 24.3s\n",
            "Epoch 2/10, train loss: 2.6469, train metric: 0.2496, valid metric: 0.1932 in 26.2s\n",
            "Epoch 3/10, train loss: 1.9874, train metric: 0.2792, valid metric: 0.2976 (best) in 27.5s\n",
            "Epoch 4/10, train loss: 1.8154, train metric: 0.3436, valid metric: 0.3608 (best) in 27.8s\n",
            "Epoch 5/10, train loss: 1.7595, train metric: 0.3641, valid metric: 0.3620 (best) in 28.2s\n",
            "Epoch 6/10, train loss: 1.7385, train metric: 0.3707, valid metric: 0.3846 (best) in 29.6s\n",
            "Epoch 7/10, train loss: 1.6966, train metric: 0.3853, valid metric: 0.3892 (best) in 29.8s\n",
            "Epoch 8/10, train loss: 1.6613, train metric: 0.3973, valid metric: 0.3728 in 32.3s\n",
            "Epoch 9/10, train loss: 1.6472, train metric: 0.4023, valid metric: 0.3940 (best) in 32.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:34:58,530] Trial 1 finished with value: 0.4050000011920929 and parameters: {'n_hidden': 4, 'n_neurons': 458, 'lr': 0.003595689013615736, 'optimizer': 'NAdam'}. Best is trial 0 with value: 0.5148000121116638.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.6356, train metric: 0.4086, valid metric: 0.4050 (best) in 34.0s\n",
            "Epoch 1/10, train loss: 1.8898, train metric: 0.3278, valid metric: 0.3536 (best) in 19.4s\n",
            "Epoch 2/10, train loss: 1.6662, train metric: 0.4059, valid metric: 0.4142 (best) in 18.7s\n",
            "Epoch 3/10, train loss: 1.5686, train metric: 0.4438, valid metric: 0.4244 (best) in 19.8s\n",
            "Epoch 4/10, train loss: 1.4981, train metric: 0.4714, valid metric: 0.4614 (best) in 18.8s\n",
            "Epoch 5/10, train loss: 1.4483, train metric: 0.4878, valid metric: 0.4736 (best) in 19.7s\n",
            "Epoch 6/10, train loss: 1.4043, train metric: 0.5054, valid metric: 0.4704 in 19.2s\n",
            "Epoch 7/10, train loss: 1.3580, train metric: 0.5226, valid metric: 0.4838 (best) in 19.5s\n",
            "Epoch 8/10, train loss: 1.3247, train metric: 0.5332, valid metric: 0.4452 in 19.8s\n",
            "Epoch 9/10, train loss: 1.2925, train metric: 0.5433, valid metric: 0.4406 in 18.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:38:11,711] Trial 2 finished with value: 0.510200023651123 and parameters: {'n_hidden': 1, 'n_neurons': 415, 'lr': 0.0006266794874801956, 'optimizer': 'NAdam'}. Best is trial 0 with value: 0.5148000121116638.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.2568, train metric: 0.5553, valid metric: 0.5102 (best) in 19.7s\n",
            "Epoch 1/10, train loss: 1.8716, train metric: 0.3352, valid metric: 0.3682 (best) in 23.9s\n",
            "Epoch 2/10, train loss: 1.6672, train metric: 0.4116, valid metric: 0.4348 (best) in 24.1s\n",
            "Epoch 3/10, train loss: 1.5776, train metric: 0.4457, valid metric: 0.4440 (best) in 24.1s\n",
            "Epoch 4/10, train loss: 1.5156, train metric: 0.4708, valid metric: 0.4462 (best) in 23.7s\n",
            "Epoch 5/10, train loss: 1.4664, train metric: 0.4839, valid metric: 0.4712 (best) in 23.9s\n",
            "Epoch 6/10, train loss: 1.4171, train metric: 0.5038, valid metric: 0.4852 (best) in 24.0s\n",
            "Epoch 7/10, train loss: 1.3782, train metric: 0.5202, valid metric: 0.4676 in 24.1s\n",
            "Epoch 8/10, train loss: 1.3408, train metric: 0.5318, valid metric: 0.5074 (best) in 24.2s\n",
            "Epoch 9/10, train loss: 1.3057, train metric: 0.5458, valid metric: 0.5042 in 23.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:42:11,432] Trial 3 finished with value: 0.5073999762535095 and parameters: {'n_hidden': 1, 'n_neurons': 724, 'lr': 0.00019650434701492584, 'optimizer': 'NAdam'}. Best is trial 0 with value: 0.5148000121116638.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.2782, train metric: 0.5541, valid metric: 0.4686 in 23.9s\n",
            "Epoch 1/10, train loss: 1.8997, train metric: 0.3253, valid metric: 0.3654 (best) in 21.7s\n",
            "Epoch 2/10, train loss: 1.7073, train metric: 0.3946, valid metric: 0.4114 (best) in 21.0s\n",
            "Epoch 3/10, train loss: 1.6237, train metric: 0.4267, valid metric: 0.4228 (best) in 21.7s\n",
            "Epoch 4/10, train loss: 1.5754, train metric: 0.4439, valid metric: 0.4424 (best) in 21.9s\n",
            "Epoch 5/10, train loss: 1.5395, train metric: 0.4577, valid metric: 0.4396 in 22.3s\n",
            "Epoch 6/10, train loss: 1.5016, train metric: 0.4716, valid metric: 0.4668 (best) in 22.1s\n",
            "Epoch 7/10, train loss: 1.4738, train metric: 0.4832, valid metric: 0.4654 in 22.0s\n",
            "Epoch 8/10, train loss: 1.4499, train metric: 0.4903, valid metric: 0.4692 (best) in 22.7s\n",
            "Epoch 9/10, train loss: 1.4216, train metric: 0.4996, valid metric: 0.4804 (best) in 22.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:45:52,253] Trial 4 finished with value: 0.4828000068664551 and parameters: {'n_hidden': 4, 'n_neurons': 381, 'lr': 3.894889966929681e-05, 'optimizer': 'AdamW'}. Best is trial 0 with value: 0.5148000121116638.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.3972, train metric: 0.5092, valid metric: 0.4828 (best) in 22.6s\n",
            "Epoch 1/10, train loss: 1.9779, train metric: 0.3173, valid metric: 0.3656 (best) in 19.1s\n",
            "Epoch 2/10, train loss: 1.7109, train metric: 0.3956, valid metric: 0.4106 (best) in 20.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:46:51,372] Trial 5 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.8714, train metric: 0.3393, valid metric: 0.3888 (best) in 19.0s\n",
            "Epoch 2/10, train loss: 1.6913, train metric: 0.4054, valid metric: 0.4020 (best) in 19.4s\n",
            "Epoch 3/10, train loss: 1.6141, train metric: 0.4360, valid metric: 0.4412 (best) in 18.5s\n",
            "Epoch 4/10, train loss: 1.5588, train metric: 0.4520, valid metric: 0.4574 (best) in 19.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:48:26,876] Trial 6 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.9010, train metric: 0.3270, valid metric: 0.3456 (best) in 23.6s\n",
            "Epoch 2/10, train loss: 1.7496, train metric: 0.3901, valid metric: 0.3916 (best) in 23.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:49:37,764] Trial 7 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.8580, train metric: 0.3437, valid metric: 0.3962 (best) in 22.4s\n",
            "Epoch 2/10, train loss: 1.6506, train metric: 0.4186, valid metric: 0.4252 (best) in 22.2s\n",
            "Epoch 3/10, train loss: 1.5733, train metric: 0.4441, valid metric: 0.4466 (best) in 21.8s\n",
            "Epoch 4/10, train loss: 1.5130, train metric: 0.4706, valid metric: 0.4682 (best) in 22.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:51:28,564] Trial 8 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.9364, train metric: 0.3290, valid metric: 0.3606 (best) in 21.3s\n",
            "Epoch 2/10, train loss: 1.6541, train metric: 0.4097, valid metric: 0.4168 (best) in 21.2s\n",
            "Epoch 3/10, train loss: 1.5639, train metric: 0.4404, valid metric: 0.4436 (best) in 21.5s\n",
            "Epoch 4/10, train loss: 1.5100, train metric: 0.4617, valid metric: 0.4630 (best) in 21.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:53:14,773] Trial 9 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.9186, train metric: 0.3229, valid metric: 0.3842 (best) in 55.1s\n",
            "Epoch 2/10, train loss: 1.7220, train metric: 0.3981, valid metric: 0.4160 (best) in 54.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 06:55:59,930] Trial 10 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.9112, train metric: 0.3187, valid metric: 0.3626 (best) in 31.8s\n",
            "Epoch 2/10, train loss: 1.6528, train metric: 0.4065, valid metric: 0.3980 (best) in 32.6s\n",
            "Epoch 3/10, train loss: 1.5221, train metric: 0.4540, valid metric: 0.4610 (best) in 32.2s\n",
            "Epoch 4/10, train loss: 1.4345, train metric: 0.4870, valid metric: 0.4350 in 32.2s\n",
            "Epoch 5/10, train loss: 1.3592, train metric: 0.5136, valid metric: 0.4952 (best) in 32.3s\n",
            "Epoch 6/10, train loss: 1.2983, train metric: 0.5360, valid metric: 0.4638 in 31.6s\n",
            "Epoch 7/10, train loss: 1.2391, train metric: 0.5585, valid metric: 0.5190 (best) in 32.4s\n",
            "Epoch 8/10, train loss: 1.1722, train metric: 0.5799, valid metric: 0.5090 in 31.8s\n",
            "Epoch 9/10, train loss: 1.1474, train metric: 0.5965, valid metric: 0.2166 in 32.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:01:22,036] Trial 11 finished with value: 0.5189999938011169 and parameters: {'n_hidden': 2, 'n_neurons': 885, 'lr': 0.000614336171320846, 'optimizer': 'NAdam'}. Best is trial 11 with value: 0.5189999938011169.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.1850, train metric: 0.5800, valid metric: 0.5172 in 32.7s\n",
            "Early stopping!\n",
            "Epoch 1/10, train loss: 13.1068, train metric: 0.1097, valid metric: 0.1008 (best) in 32.8s\n",
            "Epoch 2/10, train loss: 206.1664, train metric: 0.1073, valid metric: 0.1166 (best) in 50.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:03:36,883] Trial 12 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 2.0291, train metric: 0.2960, valid metric: 0.2950 (best) in 36.0s\n",
            "Epoch 2/10, train loss: 1.9450, train metric: 0.3570, valid metric: 0.3842 (best) in 36.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:05:26,302] Trial 13 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.8484, train metric: 0.3354, valid metric: 0.3216 (best) in 34.8s\n",
            "Epoch 2/10, train loss: 1.6151, train metric: 0.4226, valid metric: 0.4332 (best) in 35.3s\n",
            "Epoch 3/10, train loss: 1.4798, train metric: 0.4711, valid metric: 0.4388 (best) in 35.1s\n",
            "Epoch 4/10, train loss: 1.3869, train metric: 0.5023, valid metric: 0.4926 (best) in 35.4s\n",
            "Epoch 5/10, train loss: 1.3098, train metric: 0.5320, valid metric: 0.4782 in 34.8s\n",
            "Epoch 6/10, train loss: 1.2355, train metric: 0.5582, valid metric: 0.5208 (best) in 34.9s\n",
            "Epoch 7/10, train loss: 1.1577, train metric: 0.5837, valid metric: 0.5004 in 35.1s\n",
            "Epoch 8/10, train loss: 1.0850, train metric: 0.6111, valid metric: 0.5024 in 34.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:10:40,916] Trial 14 finished with value: 0.520799994468689 and parameters: {'n_hidden': 3, 'n_neurons': 804, 'lr': 0.00030369011661163464, 'optimizer': 'NAdam'}. Best is trial 14 with value: 0.520799994468689.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, train loss: 1.0096, train metric: 0.6415, valid metric: 0.5178 in 34.6s\n",
            "Early stopping!\n",
            "Epoch 1/10, train loss: 1.8370, train metric: 0.3446, valid metric: 0.4050 (best) in 26.6s\n",
            "Epoch 2/10, train loss: 1.6140, train metric: 0.4266, valid metric: 0.4186 (best) in 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:12:01,093] Trial 15 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 9.7727, train metric: 0.2250, valid metric: 0.2704 (best) in 43.8s\n",
            "Epoch 2/10, train loss: 1.8060, train metric: 0.3476, valid metric: 0.3848 (best) in 42.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:14:11,308] Trial 16 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.8181, train metric: 0.3517, valid metric: 0.3990 (best) in 41.2s\n",
            "Epoch 2/10, train loss: 1.6039, train metric: 0.4313, valid metric: 0.4022 (best) in 41.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:16:15,152] Trial 17 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, train loss: 1.8545, train metric: 0.3406, valid metric: 0.3736 (best) in 32.8s\n",
            "Epoch 2/10, train loss: 1.6144, train metric: 0.4286, valid metric: 0.4196 (best) in 33.3s\n",
            "Epoch 3/10, train loss: 1.5061, train metric: 0.4647, valid metric: 0.4414 (best) in 33.2s\n",
            "Epoch 4/10, train loss: 1.4156, train metric: 0.4954, valid metric: 0.5008 (best) in 33.6s\n",
            "Epoch 5/10, train loss: 1.3453, train metric: 0.5211, valid metric: 0.4898 in 33.5s\n",
            "Epoch 6/10, train loss: 1.2862, train metric: 0.5426, valid metric: 0.5192 (best) in 33.5s\n",
            "Epoch 7/10, train loss: 1.2230, train metric: 0.5655, valid metric: 0.5084 in 32.6s\n",
            "Epoch 8/10, train loss: 1.1704, train metric: 0.5853, valid metric: 0.5046 in 33.1s\n",
            "Epoch 9/10, train loss: 1.1156, train metric: 0.6051, valid metric: 0.5310 (best) in 32.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:21:46,596] Trial 18 finished with value: 0.531000018119812 and parameters: {'n_hidden': 2, 'n_neurons': 914, 'lr': 0.0002577197496050418, 'optimizer': 'NAdam'}. Best is trial 18 with value: 0.531000018119812.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, train loss: 1.0569, train metric: 0.6272, valid metric: 0.5262 in 32.8s\n",
            "Epoch 1/10, train loss: 1.8839, train metric: 0.3320, valid metric: 0.3686 (best) in 43.1s\n",
            "Epoch 2/10, train loss: 1.6828, train metric: 0.4088, valid metric: 0.4166 (best) in 42.2s\n",
            "Epoch 3/10, train loss: 1.5991, train metric: 0.4400, valid metric: 0.4420 (best) in 42.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2026-02-04 07:24:36,740] Trial 19 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- Optimization Complete ---\n",
            "Best Accuracy Found: 0.5310\n",
            "Best Hyperparameters:\n",
            "  n_hidden: 2\n",
            "  n_neurons: 914\n",
            "  lr: 0.0002577197496050418\n",
            "  optimizer: NAdam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = study.best_params\n",
        "params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHDIQ0qaEcNQ",
        "outputId": "8770c3fd-2d06-4626-f1f9-bcf4279c10fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_hidden': 2,\n",
              " 'n_neurons': 914,\n",
              " 'lr': 0.0002577197496050418,\n",
              " 'optimizer': 'NAdam'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reusing the best model hyperparameter to train more epochs\n",
        "\n",
        "final_model = deep_model(\n",
        "    n_hidden=params[\"n_hidden\"],\n",
        "    n_neurons=params[\"n_neurons\"],\n",
        "    n_inputs=3072,\n",
        "    n_outputs=10\n",
        ").to(device)\n",
        "\n",
        "optimizer_class = getattr(optim, params[\"optimizer\"])\n",
        "final_optimizer = optimizer_class(\n",
        "    final_model.parameters(),\n",
        "    lr=params[\"lr\"],\n",
        "    weight_decay=params.get(\"weight_decay\", 1e-4)\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    final_optimizer, mode='max', factor=0.1, patience=5\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Training (50 Epochs) ---\")\n",
        "\n",
        "final_history = train_with_early_stopping(\n",
        "    model=final_model,\n",
        "    optimizer=final_optimizer,\n",
        "    loss_fn=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    n_epochs=50,\n",
        "    patience=10,\n",
        "    device=device,\n",
        "    scheduler=scheduler,\n",
        "    checkpoint_path=\"best_cifar_mlp.pth\",\n",
        "    trial=None\n",
        ")\n",
        "\n",
        "print(\"Full training complete. Best model saved to 'best_cifar_mlp.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYPi2ykWnpvW",
        "outputId": "3258b2b6-023e-4ac7-ec86-00eca6e27fa8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Training (50 Epochs) ---\n",
            "Epoch 1/50, train loss: 1.8524, train metric: 0.3389, valid metric: 0.3842 (best) in 34.8s\n",
            "Epoch 2/50, train loss: 1.6251, train metric: 0.4241, valid metric: 0.4172 (best) in 34.5s\n",
            "Epoch 3/50, train loss: 1.5140, train metric: 0.4626, valid metric: 0.4634 (best) in 33.9s\n",
            "Epoch 4/50, train loss: 1.4256, train metric: 0.4944, valid metric: 0.4622 in 34.5s\n",
            "Epoch 5/50, train loss: 1.3563, train metric: 0.5198, valid metric: 0.4838 (best) in 35.0s\n",
            "Epoch 6/50, train loss: 1.2930, train metric: 0.5409, valid metric: 0.4554 in 34.6s\n",
            "Epoch 7/50, train loss: 1.2387, train metric: 0.5601, valid metric: 0.5266 (best) in 33.7s\n",
            "Epoch 8/50, train loss: 1.1838, train metric: 0.5815, valid metric: 0.5262 in 34.4s\n",
            "Epoch 9/50, train loss: 1.1371, train metric: 0.5963, valid metric: 0.5050 in 34.5s\n",
            "Epoch 10/50, train loss: 1.0864, train metric: 0.6158, valid metric: 0.5058 in 34.8s\n",
            "Epoch 11/50, train loss: 1.0392, train metric: 0.6318, valid metric: 0.5276 (best) in 34.6s\n",
            "Epoch 12/50, train loss: 0.9867, train metric: 0.6535, valid metric: 0.5274 in 34.3s\n",
            "Epoch 13/50, train loss: 0.9413, train metric: 0.6671, valid metric: 0.5298 (best) in 34.8s\n",
            "Epoch 14/50, train loss: 0.8931, train metric: 0.6836, valid metric: 0.5240 in 35.0s\n",
            "Epoch 15/50, train loss: 0.8471, train metric: 0.7016, valid metric: 0.5374 (best) in 35.3s\n",
            "Epoch 16/50, train loss: 0.7992, train metric: 0.7194, valid metric: 0.5182 in 34.2s\n",
            "Epoch 17/50, train loss: 0.7527, train metric: 0.7374, valid metric: 0.5424 (best) in 34.5s\n",
            "Epoch 18/50, train loss: 0.7091, train metric: 0.7522, valid metric: 0.5430 (best) in 34.2s\n",
            "Epoch 19/50, train loss: 0.6621, train metric: 0.7702, valid metric: 0.5408 in 34.4s\n",
            "Epoch 20/50, train loss: 0.6203, train metric: 0.7866, valid metric: 0.5378 in 35.0s\n",
            "Epoch 21/50, train loss: 0.5778, train metric: 0.8033, valid metric: 0.5542 (best) in 34.2s\n",
            "Epoch 22/50, train loss: 0.5363, train metric: 0.8181, valid metric: 0.5432 in 34.7s\n",
            "Epoch 23/50, train loss: 0.4974, train metric: 0.8316, valid metric: 0.5382 in 34.6s\n",
            "Epoch 24/50, train loss: 0.4616, train metric: 0.8462, valid metric: 0.5520 in 34.6s\n",
            "Epoch 25/50, train loss: 0.4269, train metric: 0.8591, valid metric: 0.5420 in 33.9s\n",
            "Epoch 26/50, train loss: 0.3956, train metric: 0.8720, valid metric: 0.5444 in 34.4s\n",
            "Epoch 27/50, train loss: 0.3648, train metric: 0.8802, valid metric: 0.5366 in 34.5s\n",
            "Epoch 28/50, train loss: 0.2406, train metric: 0.9345, valid metric: 0.5672 (best) in 34.1s\n",
            "Epoch 29/50, train loss: 0.2176, train metric: 0.9440, valid metric: 0.5660 in 33.6s\n",
            "Epoch 30/50, train loss: 0.2112, train metric: 0.9454, valid metric: 0.5690 (best) in 34.8s\n",
            "Epoch 31/50, train loss: 0.2055, train metric: 0.9481, valid metric: 0.5662 in 34.8s\n",
            "Epoch 32/50, train loss: 0.2009, train metric: 0.9499, valid metric: 0.5648 in 35.5s\n",
            "Epoch 33/50, train loss: 0.1958, train metric: 0.9514, valid metric: 0.5626 in 35.4s\n",
            "Epoch 34/50, train loss: 0.1915, train metric: 0.9536, valid metric: 0.5640 in 35.0s\n",
            "Epoch 35/50, train loss: 0.1876, train metric: 0.9541, valid metric: 0.5634 in 35.3s\n",
            "Epoch 36/50, train loss: 0.1829, train metric: 0.9566, valid metric: 0.5628 in 35.6s\n",
            "Epoch 37/50, train loss: 0.1680, train metric: 0.9632, valid metric: 0.5662 in 35.3s\n",
            "Epoch 38/50, train loss: 0.1656, train metric: 0.9631, valid metric: 0.5658 in 35.3s\n",
            "Epoch 39/50, train loss: 0.1648, train metric: 0.9637, valid metric: 0.5656 in 35.3s\n",
            "Epoch 40/50, train loss: 0.1642, train metric: 0.9640, valid metric: 0.5662 in 35.1s\n",
            "Early stopping!\n",
            "Full training complete. Best model saved to 'best_cifar_mlp.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2470, 0.2435, 0.2616]\n",
        "    ),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])"
      ],
      "metadata": {
        "id": "bp-meERAqZzD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepMLP_SELU(nn.Module):\n",
        "    def __init__(self, n_inputs, n_hidden, n_neurons, n_outputs):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "\n",
        "        in_features = n_inputs\n",
        "        for _ in range(n_hidden):\n",
        "            linear = nn.Linear(in_features, n_neurons)\n",
        "            nn.init.normal_(linear.weight, mean=0.0, std=(1 / in_features) ** 0.5)\n",
        "            nn.init.zeros_(linear.bias)\n",
        "\n",
        "            layers.append(linear)\n",
        "            layers.append(nn.SELU())\n",
        "            in_features = n_neurons\n",
        "\n",
        "        out = nn.Linear(in_features, n_outputs)\n",
        "        nn.init.normal_(out.weight, mean=0.0, std=(1 / in_features) ** 0.5)\n",
        "        nn.init.zeros_(out.bias)\n",
        "\n",
        "        layers.append(out)\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "LHa4b3I8x7R8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "selu_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2470, 0.2435, 0.2616]\n",
        "    ),\n",
        "])\n"
      ],
      "metadata": {
        "id": "AXHbM9yxyeu6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_valid_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"datasets\", train=True, download=True, transform=selu_transform)\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root=\"datasets\", train=False, download=True, transform=selu_transform)"
      ],
      "metadata": {
        "id": "f84Z34dsyFlr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = DeepMLP_SELU(\n",
        "    n_inputs=3072,\n",
        "    n_hidden=params[\"n_hidden\"],\n",
        "    n_neurons=params[\"n_neurons\"],\n",
        "    n_outputs=10\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "70Jxg9gByJeb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_history_selu = train_with_early_stopping(\n",
        "    model=final_model,\n",
        "    optimizer=final_optimizer,\n",
        "    loss_fn=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    n_epochs=50,\n",
        "    patience=10,\n",
        "    device=device,\n",
        "    scheduler=scheduler,\n",
        "    checkpoint_path=\"best_cifar_mlp_selu.pth\",\n",
        "    trial=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y--11Odwysmh",
        "outputId": "2e2b5503-40c0-4c67-bce2-02a97e31ee6e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, train loss: 2.4382, train metric: 0.0981, valid metric: 0.0998 (best) in 26.8s\n",
            "Epoch 2/50, train loss: 2.4382, train metric: 0.0981, valid metric: 0.0998 in 26.9s\n",
            "Epoch 3/50, train loss: 2.4381, train metric: 0.0981, valid metric: 0.0998 in 27.1s\n",
            "Epoch 4/50, train loss: 2.4381, train metric: 0.0981, valid metric: 0.0998 in 26.4s\n",
            "Epoch 5/50, train loss: 2.4381, train metric: 0.0981, valid metric: 0.0998 in 26.9s\n",
            "Epoch 6/50, train loss: 2.4382, train metric: 0.0981, valid metric: 0.0998 in 26.4s\n",
            "Epoch 7/50, train loss: 2.4382, train metric: 0.0981, valid metric: 0.0998 in 26.5s\n",
            "Epoch 8/50, train loss: 2.4381, train metric: 0.0981, valid metric: 0.0998 in 26.5s\n",
            "Epoch 9/50, train loss: 2.4382, train metric: 0.0981, valid metric: 0.0998 in 26.6s\n",
            "Epoch 10/50, train loss: 2.4381, train metric: 0.0981, valid metric: 0.0998 in 27.6s\n",
            "Epoch 11/50, train loss: 2.4382, train metric: 0.0981, valid metric: 0.0998 in 26.8s\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_model_dropout(n_hidden, n_neurons, n_inputs, n_outputs, p=0.2):\n",
        "\n",
        "    layers = [\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(n_inputs, n_neurons),\n",
        "        nn.SiLU(),\n",
        "        nn.Dropout(p)\n",
        "    ]\n",
        "\n",
        "    for _ in range(n_hidden - 1):\n",
        "        layers += [\n",
        "            nn.Linear(n_neurons, n_neurons),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(p)\n",
        "        ]\n",
        "\n",
        "    layers += [nn.Linear(n_neurons, n_outputs)]\n",
        "\n",
        "    model = nn.Sequential(*layers)\n",
        "    model.apply(use_he_init)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "oSQIUEYRyvFe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_class = getattr(torch.optim, params[\"optimizer\"])\n",
        "\n",
        "optimizer = optimizer_class(\n",
        "    model.parameters(),\n",
        "    lr=params[\"lr\"]\n",
        ")"
      ],
      "metadata": {
        "id": "ZbxYOKyr4NcR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'n_hidden': 2,\n",
        "    'n_neurons': 914,\n",
        "    'lr': 0.0002577197496050418,\n",
        "    'optimizer': 'NAdam'\n",
        "}\n",
        "\n",
        "model = deep_model_dropout(\n",
        "    n_hidden=params[\"n_hidden\"],\n",
        "    n_neurons=params[\"n_neurons\"],\n",
        "    n_inputs=3072,\n",
        "    n_outputs=10,\n",
        "    p=0.2\n",
        ").to(device)\n",
        "\n",
        "optimizer_class = getattr(torch.optim, params[\"optimizer\"])\n",
        "optimizer = optimizer_class(\n",
        "    model.parameters(),\n",
        "    lr=params[\"lr\"]\n",
        ")\n",
        "\n",
        "best_acc = train_with_early_stopping(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    n_epochs=50,\n",
        "    patience=10,\n",
        "    device=device,\n",
        "    checkpoint_path=\"best_mlp_dropout.pth\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54jGTKn63eq0",
        "outputId": "6f44edf8-b15f-45ed-d880-f4161385e18e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, train loss: 1.8931, train metric: 0.3195, valid metric: 0.4062 (best) in 35.2s\n",
            "Epoch 2/50, train loss: 1.6828, train metric: 0.4000, valid metric: 0.4356 (best) in 35.3s\n",
            "Epoch 3/50, train loss: 1.5872, train metric: 0.4338, valid metric: 0.3934 in 34.8s\n",
            "Epoch 4/50, train loss: 1.5175, train metric: 0.4599, valid metric: 0.4300 in 35.3s\n",
            "Epoch 5/50, train loss: 1.4582, train metric: 0.4778, valid metric: 0.4782 (best) in 34.2s\n",
            "Epoch 6/50, train loss: 1.4055, train metric: 0.4977, valid metric: 0.4670 in 35.0s\n",
            "Epoch 7/50, train loss: 1.3629, train metric: 0.5117, valid metric: 0.4838 (best) in 34.9s\n",
            "Epoch 8/50, train loss: 1.3247, train metric: 0.5260, valid metric: 0.5122 (best) in 35.5s\n",
            "Epoch 9/50, train loss: 1.2875, train metric: 0.5409, valid metric: 0.5094 in 35.3s\n",
            "Epoch 10/50, train loss: 1.2569, train metric: 0.5527, valid metric: 0.5256 (best) in 34.6s\n",
            "Epoch 11/50, train loss: 1.2215, train metric: 0.5652, valid metric: 0.5250 in 35.2s\n",
            "Epoch 12/50, train loss: 1.1937, train metric: 0.5740, valid metric: 0.5392 (best) in 35.1s\n",
            "Epoch 13/50, train loss: 1.1609, train metric: 0.5863, valid metric: 0.5270 in 35.1s\n",
            "Epoch 14/50, train loss: 1.1336, train metric: 0.5944, valid metric: 0.5446 (best) in 35.3s\n",
            "Epoch 15/50, train loss: 1.1027, train metric: 0.6038, valid metric: 0.5260 in 34.3s\n",
            "Epoch 16/50, train loss: 1.0720, train metric: 0.6156, valid metric: 0.5378 in 34.9s\n",
            "Epoch 17/50, train loss: 1.0471, train metric: 0.6253, valid metric: 0.5266 in 35.1s\n",
            "Epoch 18/50, train loss: 1.0226, train metric: 0.6356, valid metric: 0.5630 (best) in 35.2s\n",
            "Epoch 19/50, train loss: 0.9958, train metric: 0.6461, valid metric: 0.5446 in 35.7s\n",
            "Epoch 20/50, train loss: 0.9639, train metric: 0.6567, valid metric: 0.5506 in 34.3s\n",
            "Epoch 21/50, train loss: 0.9399, train metric: 0.6623, valid metric: 0.5576 in 35.3s\n",
            "Epoch 22/50, train loss: 0.9152, train metric: 0.6724, valid metric: 0.5574 in 35.3s\n",
            "Epoch 23/50, train loss: 0.8899, train metric: 0.6800, valid metric: 0.5530 in 35.5s\n",
            "Epoch 24/50, train loss: 0.8660, train metric: 0.6896, valid metric: 0.5620 in 35.6s\n",
            "Epoch 25/50, train loss: 0.8385, train metric: 0.7005, valid metric: 0.5678 (best) in 34.9s\n",
            "Epoch 26/50, train loss: 0.8181, train metric: 0.7062, valid metric: 0.5716 (best) in 34.8s\n",
            "Epoch 27/50, train loss: 0.7939, train metric: 0.7153, valid metric: 0.5656 in 35.3s\n",
            "Epoch 28/50, train loss: 0.7700, train metric: 0.7245, valid metric: 0.5656 in 35.4s\n",
            "Epoch 29/50, train loss: 0.7495, train metric: 0.7290, valid metric: 0.5686 in 35.4s\n",
            "Epoch 30/50, train loss: 0.7302, train metric: 0.7369, valid metric: 0.5692 in 35.4s\n",
            "Epoch 31/50, train loss: 0.7035, train metric: 0.7478, valid metric: 0.5668 in 35.0s\n",
            "Epoch 32/50, train loss: 0.6828, train metric: 0.7559, valid metric: 0.5632 in 35.4s\n",
            "Epoch 33/50, train loss: 0.6650, train metric: 0.7609, valid metric: 0.5612 in 35.5s\n",
            "Epoch 34/50, train loss: 0.6475, train metric: 0.7689, valid metric: 0.5704 in 35.6s\n",
            "Epoch 35/50, train loss: 0.6260, train metric: 0.7750, valid metric: 0.5694 in 35.5s\n",
            "Epoch 36/50, train loss: 0.6097, train metric: 0.7822, valid metric: 0.5670 in 35.7s\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def standard_accuracy(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x).argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "0DpTVfaX3hBD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_acc = standard_accuracy(model, valid_loader, device)\n",
        "print(f\"Standard accuracy: {std_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1c0PiDA3sf_",
        "outputId": "6846038d-2ef6-4aaa-def8-f302be4f44a4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy: 0.5716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_dropout(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Dropout):\n",
        "            m.train()\n"
      ],
      "metadata": {
        "id": "EwmNsU9Y3vUM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "@torch.no_grad()\n",
        "def mc_dropout_accuracy(model, dataloader, device, n_samples=30):\n",
        "    model.eval()\n",
        "    enable_dropout(model)\n",
        "\n",
        "    probs_mc = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        probs = []\n",
        "        targets = []\n",
        "\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            probs.append(F.softmax(logits, dim=1))\n",
        "            targets.append(y)\n",
        "\n",
        "        probs_mc.append(torch.cat(probs))\n",
        "\n",
        "    mean_probs = torch.stack(probs_mc).mean(dim=0)\n",
        "    preds = mean_probs.argmax(dim=1)\n",
        "    targets = torch.cat(targets)\n",
        "\n",
        "    return (preds == targets).float().mean().item()\n"
      ],
      "metadata": {
        "id": "oy2VcmG23wMS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_acc = mc_dropout_accuracy(model, valid_loader, device, n_samples=30)\n",
        "\n",
        "print(f\"Standard accuracy : {std_acc:.4f}\")\n",
        "print(f\"MC Dropout accuracy: {mc_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctudaxeC30Bq",
        "outputId": "72b64f49-1d3c-40f2-9614-680b4a964fed"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy : 0.5716\n",
            "MC Dropout accuracy: 0.5714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BAKNUFTx-DRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}